{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model and corpus data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"fasttext_unsupervised_cbow_dim300_preprocessing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model vocabulary and embeddings \n",
    "import fasttext\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "model = fasttext.load_model(f\"models/{model_name}.bin\")\n",
    "\n",
    "vocabulary = model.words\n",
    "word_embeddings = np.array([model[word] for word in vocabulary])\n",
    "\n",
    "# Clean memory\n",
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read preprocessed docs texts from file\n",
    "input_file_name = 'preprocessed_texts.txt'\n",
    "with open(input_file_name, 'r', encoding='utf-8') as file:\n",
    "    preprocessed_texts = file.readlines()\n",
    "\n",
    "preprocessed_texts = [text.strip() for text in preprocessed_texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate words of each document\n",
    "Since both the documents and the query is of variable size, we should aggregate the vectors of the words in the query by some strategy. This could be taking the minimum vector, maximum vector or the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of vectors for easier search\n",
    "vector_dict = dict(zip(vocabulary, word_embeddings))\n",
    "\n",
    "def aggregate_vector_list(vlist, aggfunc):\n",
    "    if aggfunc == 'max':\n",
    "        return np.array(vlist).max(axis=0)\n",
    "    elif aggfunc == 'min':\n",
    "        return np.array(vlist).min(axis=0)\n",
    "    elif aggfunc == 'mean':\n",
    "        return np.array(vlist).mean(axis=0)\n",
    "    else:\n",
    "        return np.zeros(np.array(vlist).shape[1])\n",
    "\n",
    "# possible_aggfuncs = [\"max\", \"min\", \"mean\"]\n",
    "possible_aggfuncs = [\"mean\"]\n",
    "\n",
    "aggregated_docs_vectors = {} # for each doc, the 3 possible aggregated vectors (min, max, mean)\n",
    "\n",
    "# Aggregate vectors of documents\n",
    "for aggfunc in possible_aggfuncs:\n",
    "    aggregated_docs_vectors[aggfunc] = np.zeros((len(preprocessed_texts), word_embeddings.shape[1]))\n",
    "    for index, doc in enumerate(preprocessed_texts):\n",
    "        vlist = [vector_dict[token] for token in fasttext.tokenize(doc) if token in vector_dict]\n",
    "        if(len(vlist) < 1):\n",
    "            continue \n",
    "        else:\n",
    "            aggregated_docs_vectors[aggfunc][index] = aggregate_vector_list(vlist, aggfunc)\n",
    "\n",
    "del vocabulary\n",
    "del word_embeddings\n",
    "del vector_dict\n",
    "del preprocessed_texts\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the aggregated vectors calculated for each document on disk\n",
    "import pickle\n",
    "\n",
    "aggregated_docs_vectors_file = model_name\n",
    "\n",
    "# Save aggregated_docs_vectors to disk\n",
    "with open(f'aggregated_docs_vectors/adv_{aggregated_docs_vectors_file}.pkl', 'wb') as f:\n",
    "    pickle.dump(aggregated_docs_vectors, f)\n",
    "print(f\"Saved aggregated_docs_vectors to aggregated_docs_vectors/adv_{aggregated_docs_vectors_file}.pkl\")\n",
    "\n",
    "# Clean memory\n",
    "del aggregated_docs_vectors\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
